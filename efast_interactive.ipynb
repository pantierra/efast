{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# eFAST Interactive Runner\n",
    "\n",
    "Select a site and season, then run eFAST processing and visualization.\n",
    "\n",
    "**Setup:**\n",
    "```bash\n",
    "pip install ipywidgets matplotlib rasterio numpy\n",
    "jupyter nbextension enable --py widgetsnbextension\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from pathlib import Path\n",
    "from datetime import datetime, timedelta\n",
    "from dateutil.rrule import rrule, DAILY\n",
    "from IPython.display import display\n",
    "import ipywidgets as widgets\n",
    "\n",
    "try:\n",
    "    import rasterio\n",
    "    import matplotlib.pyplot as plt\n",
    "    import numpy as np\n",
    "    RASTERIO_AVAILABLE = True\n",
    "except ImportError:\n",
    "    RASTERIO_AVAILABLE = False\n",
    "    print(\"‚ö†Ô∏è Install rasterio for visualization: pip install rasterio matplotlib numpy\")\n",
    "\n",
    "try:\n",
    "    import efast\n",
    "    EFAST_AVAILABLE = True\n",
    "except ImportError:\n",
    "    EFAST_AVAILABLE = False\n",
    "    print(\"‚ö†Ô∏è Install efast package: pip install -e .\")\n",
    "\n",
    "try:\n",
    "    import run_efast\n",
    "    RUN_EFAST_AVAILABLE = True\n",
    "except ImportError:\n",
    "    RUN_EFAST_AVAILABLE = False\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Site Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d0a85f098ef24f74906f4d67171f3094",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(HTML(value='<h3>Select Site and Season</h3>'), HBox(children=(Dropdown(description='Site:', ind‚Ä¶"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Load sites\n",
    "with open('selected_sites.geojson', 'r') as f:\n",
    "    geojson_data = json.load(f)\n",
    "\n",
    "sites = {}\n",
    "for feature in geojson_data['features']:\n",
    "    props = feature['properties']\n",
    "    sitename = props['sitename']\n",
    "    sites[sitename] = {\n",
    "        'coordinates': feature['geometry']['coordinates'],\n",
    "        'description': props.get('description', ''),\n",
    "        'seasons': props.get('seasons', {})\n",
    "    }\n",
    "\n",
    "# Create widgets\n",
    "site_dropdown = widgets.Dropdown(options=sorted(sites.keys()), description='Site:', style={'description_width': '100px'})\n",
    "season_dropdown = widgets.Dropdown(options=[], description='Season:', style={'description_width': '100px'})\n",
    "info_output = widgets.Output()\n",
    "\n",
    "def update_season(change=None):\n",
    "    if site_dropdown.value:\n",
    "        seasons = sorted(sites[site_dropdown.value]['seasons'].keys(), reverse=True)\n",
    "        season_dropdown.options = seasons\n",
    "        if seasons:\n",
    "            season_dropdown.value = seasons[0] if '2024' not in seasons else '2024'\n",
    "    \n",
    "    with info_output:\n",
    "        info_output.clear_output()\n",
    "        if site_dropdown.value and season_dropdown.value:\n",
    "            site = sites[site_dropdown.value]\n",
    "            season_data = site['seasons'][season_dropdown.value]\n",
    "            print(f\"üìç {site_dropdown.value}\")\n",
    "            print(f\"üìÖ {season_data['season_start_date']} to {season_data['season_end_date']}\")\n",
    "            print(f\"üõ∞Ô∏è S2: {season_data['sentinel2_scenes']} scenes | S3: {season_data['sentinel3_scenes']} scenes\")\n",
    "\n",
    "site_dropdown.observe(update_season, names='value')\n",
    "\n",
    "# Initialize\n",
    "if 'innsbruck' in site_dropdown.options:\n",
    "    site_dropdown.value = 'innsbruck'\n",
    "else:\n",
    "    site_dropdown.value = site_dropdown.options[0]\n",
    "update_season()\n",
    "\n",
    "display(widgets.VBox([\n",
    "    widgets.HTML(\"<h3>Select Site and Season</h3>\"),\n",
    "    widgets.HBox([site_dropdown, season_dropdown]),\n",
    "    info_output\n",
    "]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Get Data\n",
    "\n",
    "Download S2 and S3 data from CDSE, or use cached data if available.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "üìä DATA STATUS\n",
      "============================================================\n",
      "S2 Raw: ‚ùå 0 files\n",
      "S3 Raw: ‚ùå 0 files\n",
      "============================================================\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b40bfcebaaff419ebce0f6d65d51ab9b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Button(button_style='primary', description='üì• Download Data', disabled=True, style=ButtonStyle(‚Ä¶"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======================================================================\n",
      "üìä EFAST PIPELINE STATUS\n",
      "======================================================================\n",
      "Site: innsbruck | Season: 2024\n",
      "Date range: 2024-01-01 to 2024-12-31\n",
      "\n",
      "1Ô∏è‚É£  DOWNLOAD\n",
      "   S2 Raw: ‚ùå 0 files\n",
      "   S3 Raw: ‚ùå 0 files\n",
      "\n",
      "2Ô∏è‚É£  S2 PROCESSING\n",
      "   Processed: ‚úÖ 1 files\n",
      "\n",
      "3Ô∏è‚É£  S3 PROCESSING\n",
      "   Binning: ‚úÖ 365 files\n",
      "   Composites: ‚úÖ 183 files\n",
      "   Reprojected: ‚úÖ 183 files\n",
      "\n",
      "4Ô∏è‚É£  FUSION\n",
      "   Results: ‚ùå 0 files\n",
      "\n",
      "======================================================================\n",
      "\n",
      "======================================================================\n",
      "üìÇ Loading data for verification...\n",
      "======================================================================\n",
      "‚úÖ Loaded:\n",
      "   Fusion files: 0\n",
      "   S2 files: 1\n",
      "   S3 composites: 183\n",
      "======================================================================\n"
     ]
    }
   ],
   "source": [
    "# Check data availability and download\n",
    "test_data_dir = Path('test_data')\n",
    "s2_raw_dir = test_data_dir / 'S2' / 'raw'\n",
    "s3_raw_dir = test_data_dir / 'S3' / 'raw'\n",
    "\n",
    "# Ensure RUN_EFAST_AVAILABLE is defined (fallback if imports cell wasn't run)\n",
    "if 'RUN_EFAST_AVAILABLE' not in globals():\n",
    "    try:\n",
    "        import run_efast\n",
    "        RUN_EFAST_AVAILABLE = True\n",
    "    except ImportError:\n",
    "        RUN_EFAST_AVAILABLE = False\n",
    "\n",
    "# Get selected site/season\n",
    "sitename = site_dropdown.value if 'site_dropdown' in globals() else None\n",
    "season_year = season_dropdown.value if 'season_dropdown' in globals() else None\n",
    "start_date = None\n",
    "end_date = None\n",
    "\n",
    "if sitename and season_year and sitename in sites:\n",
    "    if season_year in sites[sitename]['seasons']:\n",
    "        season_data = sites[sitename]['seasons'][season_year]\n",
    "        start_date = season_data.get('season_start_date')\n",
    "        end_date = season_data.get('season_end_date')\n",
    "\n",
    "# Check cache\n",
    "s2_files = list(s2_raw_dir.glob('*.SAFE')) if s2_raw_dir.exists() else []\n",
    "s3_files = list(s3_raw_dir.glob('*.zip')) + list(s3_raw_dir.glob('*.nc')) if s3_raw_dir.exists() else []\n",
    "\n",
    "download_output = widgets.Output()\n",
    "download_button = widgets.Button(\n",
    "    description='üì• Download Data',\n",
    "    button_style='primary',\n",
    "    disabled=not (RUN_EFAST_AVAILABLE and start_date and end_date)\n",
    ")\n",
    "\n",
    "def run_download(b):\n",
    "    with download_output:\n",
    "        download_output.clear_output()\n",
    "        if not start_date or not end_date:\n",
    "            print(\"‚ùå Select site and season first\")\n",
    "            return\n",
    "        \n",
    "        if s2_files and s3_files:\n",
    "            print(f\"‚úÖ Data already cached: S2={len(s2_files)} files, S3={len(s3_files)} files\")\n",
    "            print(\"üí° Click again to re-download\")\n",
    "            return\n",
    "        \n",
    "        print(f\"üì• Downloading data for {start_date} to {end_date}...\")\n",
    "        \n",
    "        coords = sites[sitename]['coordinates']\n",
    "        aoi_geometry = f\"POINT ({coords[0]} {coords[1]})\"\n",
    "        \n",
    "        try:\n",
    "            credentials = run_efast.get_credentials_from_env()\n",
    "        except:\n",
    "            print(\"‚ùå CDSE credentials not found. Set CDSE_USERNAME and CDSE_PASSWORD\")\n",
    "            return\n",
    "        \n",
    "        s2_raw_dir.mkdir(parents=True, exist_ok=True)\n",
    "        s3_raw_dir.mkdir(parents=True, exist_ok=True)\n",
    "        \n",
    "        try:\n",
    "            run_efast.download_data(\n",
    "                start_date, end_date, aoi_geometry,\n",
    "                s2_raw_dir, s3_raw_dir, credentials, data_source=\"cdse\"\n",
    "            )\n",
    "            print(f\"‚úÖ Download complete!\")\n",
    "            print(f\"üí° Re-run this cell to refresh status\")\n",
    "        except Exception as e:\n",
    "            print(f\"‚ùå Error: {e}\")\n",
    "            import traceback\n",
    "            traceback.print_exc()\n",
    "\n",
    "download_button.on_click(run_download)\n",
    "\n",
    "print(\"=\" * 60)\n",
    "print(\"üìä DATA STATUS\")\n",
    "print(\"=\" * 60)\n",
    "print(f\"S2 Raw: {'‚úÖ' if s2_files else '‚ùå'} {len(s2_files)} files\")\n",
    "print(f\"S3 Raw: {'‚úÖ' if s3_files else '‚ùå'} {len(s3_files)} files\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "display(widgets.VBox([download_button, download_output]))\n",
    "\n",
    "# Load data for verification cells (runs silently - status shown in individual step cells)\n",
    "if RASTERIO_AVAILABLE and test_data_dir.exists():\n",
    "    # Load fusion files\n",
    "    fusion_dir = test_data_dir / 'fusion_results'\n",
    "    fusion_files = sorted(fusion_dir.glob('REFL_*.tif')) if fusion_dir.exists() else []\n",
    "    \n",
    "    # Filter by date range\n",
    "    filtered_fusion = []\n",
    "    if start_date and end_date and fusion_files:\n",
    "        for f in fusion_files:\n",
    "            try:\n",
    "                date_str = f.stem.split('REFL_')[1].split('_')[0]\n",
    "                if len(date_str) == 8:\n",
    "                    file_date = f\"{date_str[:4]}-{date_str[4:6]}-{date_str[6:8]}\"\n",
    "                    if start_date <= file_date <= end_date:\n",
    "                        filtered_fusion.append(f)\n",
    "            except (IndexError, ValueError):\n",
    "                pass\n",
    "    else:\n",
    "        filtered_fusion = fusion_files\n",
    "    \n",
    "    # Load S2 and S3 files\n",
    "    s2_dir = test_data_dir / 'S2' / 'processed'\n",
    "    s2_files = sorted(s2_dir.glob('*REFL.tif')) if s2_dir.exists() else []\n",
    "    \n",
    "    s3_composites_dir = test_data_dir / 'S3' / 'composites'\n",
    "    s3_composites = sorted(s3_composites_dir.glob('composite*.tif')) if s3_composites_dir.exists() else []\n",
    "else:\n",
    "    # Initialize empty if not available\n",
    "    filtered_fusion = []\n",
    "    s2_files = []\n",
    "    s3_composites = []"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Processing\n",
    "\n",
    "Process S2 (extract and mask bands) and S3 (bin, composite, smooth, reproject) data. Uses cached results if available.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "üìä PROCESSING STATUS\n",
      "============================================================\n",
      "S2 Processed: ‚úÖ 1 files\n",
      "S3 Reprojected: ‚úÖ 183 files\n",
      "============================================================\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "80b1c92848d24e1595df26f61fc4e418",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Button(button_style='info', description='‚öôÔ∏è Process Data', disabled=True, style=ButtonStyle()),‚Ä¶"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Check processing status\n",
    "s2_processed_dir = test_data_dir / 'S2' / 'processed'\n",
    "s3_reprojected_dir = test_data_dir / 'S3' / 'reprojected'\n",
    "\n",
    "s2_processed = list(s2_processed_dir.glob('*REFL.tif')) if s2_processed_dir.exists() else []\n",
    "s3_reprojected = list(s3_reprojected_dir.glob('composite*.tif')) if s3_reprojected_dir.exists() else []\n",
    "\n",
    "process_output = widgets.Output()\n",
    "process_button = widgets.Button(\n",
    "    description='‚öôÔ∏è Process Data',\n",
    "    button_style='info',\n",
    "    disabled=not (EFAST_AVAILABLE and s2_files and s3_files)\n",
    ")\n",
    "\n",
    "def run_processing(b):\n",
    "    with process_output:\n",
    "        process_output.clear_output()\n",
    "        \n",
    "        if not s2_files or not s3_files:\n",
    "            print(\"‚ùå Download data first\")\n",
    "            return\n",
    "        \n",
    "        if s2_processed and s3_reprojected:\n",
    "            print(f\"‚úÖ Processing already done: S2={len(s2_processed)} files, S3={len(s3_reprojected)} files\")\n",
    "            print(\"üí° Click again to re-process\")\n",
    "            return\n",
    "        \n",
    "        print(\"‚öôÔ∏è Processing data...\")\n",
    "        \n",
    "        try:\n",
    "            import efast.s2_processing as s2\n",
    "            import efast.s3_processing as s3\n",
    "            \n",
    "            # S2 Processing\n",
    "            print(\"\\nüõ∞Ô∏è Processing S2...\")\n",
    "            s2_processed_dir.mkdir(parents=True, exist_ok=True)\n",
    "            s2.extract_mask_s2_bands(s2_raw_dir, s2_processed_dir, bands=[\"B02\", \"B03\", \"B04\", \"B8A\"])\n",
    "            s2.distance_to_clouds(s2_processed_dir, ratio=30)\n",
    "            \n",
    "            # S3 Processing\n",
    "            print(\"\\nüåä Processing S3...\")\n",
    "            footprint = s2.get_wkt_footprint(s2_processed_dir)\n",
    "            \n",
    "            s3_binning_dir = test_data_dir / 'S3' / 'binning'\n",
    "            s3_composites_dir = test_data_dir / 'S3' / 'composites'\n",
    "            s3_blurred_dir = test_data_dir / 'S3' / 'blurred'\n",
    "            s3_calibrated_dir = test_data_dir / 'S3' / 'calibrated'\n",
    "            \n",
    "            for d in [s3_binning_dir, s3_composites_dir, s3_blurred_dir, s3_calibrated_dir, s3_reprojected_dir]:\n",
    "                d.mkdir(parents=True, exist_ok=True)\n",
    "            \n",
    "            s3.binning_s3(s3_raw_dir, s3_binning_dir, footprint=footprint,\n",
    "                        s3_bands=[\"SDR_Oa04\", \"SDR_Oa06\", \"SDR_Oa08\", \"SDR_Oa17\"],\n",
    "                        instrument=\"OL\", aggregator=\"mean\")\n",
    "            s3.produce_median_composite(s3_binning_dir, s3_composites_dir, mosaic_days=100, step=2)\n",
    "            s3.smoothing(s3_composites_dir, s3_blurred_dir, std=1, preserve_nan=False)\n",
    "            s3.reformat_s3(s3_blurred_dir, s3_calibrated_dir)\n",
    "            s3.reproject_and_crop_s3(s3_calibrated_dir, s2_processed_dir, s3_reprojected_dir)\n",
    "            \n",
    "            print(f\"\\n‚úÖ Processing complete!\")\n",
    "            print(f\"üí° Re-run this cell to refresh status\")\n",
    "        except Exception as e:\n",
    "            print(f\"‚ùå Error: {e}\")\n",
    "            import traceback\n",
    "            traceback.print_exc()\n",
    "\n",
    "process_button.on_click(run_processing)\n",
    "\n",
    "print(\"=\" * 60)\n",
    "print(\"üìä PROCESSING STATUS\")\n",
    "print(\"=\" * 60)\n",
    "print(f\"S2 Processed: {'‚úÖ' if s2_processed else '‚ùå'} {len(s2_processed)} files\")\n",
    "print(f\"S3 Reprojected: {'‚úÖ' if s3_reprojected else '‚ùå'} {len(s3_reprojected)} files\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "display(widgets.VBox([process_button, process_output]))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Fusion\n",
    "\n",
    "Combine S2 and S3 into high-resolution daily images. Uses cached results if available."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "üìä FUSION STATUS\n",
      "============================================================\n",
      "Fusion Results: ‚ùå 0 files\n",
      "Date range: 2024-01-01 to 2024-12-31\n",
      "============================================================\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2ce3433a384648c19b00fb8d4143d4d5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Button(button_style='success', description='üöÄ Run Fusion', style=ButtonStyle()), Output()))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Check fusion status\n",
    "fusion_dir = test_data_dir / 'fusion_results'\n",
    "fusion_files = sorted(fusion_dir.glob('REFL_*.tif')) if fusion_dir.exists() else []\n",
    "\n",
    "# Use filtered_fusion from Cell 5 if available, otherwise count all files\n",
    "if 'filtered_fusion' in globals():\n",
    "    fusion_count = len(filtered_fusion)\n",
    "else:\n",
    "    fusion_count = len(fusion_files)\n",
    "\n",
    "fusion_output = widgets.Output()\n",
    "fusion_button = widgets.Button(\n",
    "    description='üöÄ Run Fusion',\n",
    "    button_style='success',\n",
    "    disabled=not (EFAST_AVAILABLE and s2_processed and s3_reprojected and start_date and end_date)\n",
    ")\n",
    "\n",
    "def run_fusion(b):\n",
    "    with fusion_output:\n",
    "        fusion_output.clear_output()\n",
    "        \n",
    "        if not s2_processed or not s3_reprojected:\n",
    "            print(\"‚ùå Process S2 and S3 data first\")\n",
    "            return\n",
    "        \n",
    "        if not start_date or not end_date:\n",
    "            print(\"‚ùå Select site and season first\")\n",
    "            return\n",
    "        \n",
    "        if fusion_count > 0:\n",
    "            print(f\"‚úÖ Fusion already done: {fusion_count} files\")\n",
    "            print(\"üí° Click again to re-run fusion\")\n",
    "            return\n",
    "        \n",
    "        print(f\"üöÄ Running fusion for {start_date} to {end_date}...\")\n",
    "        \n",
    "        try:\n",
    "            fusion_dir.mkdir(parents=True, exist_ok=True)\n",
    "            \n",
    "            step = 2\n",
    "            ratio = 30\n",
    "            max_days = 15\n",
    "            minimum_acquisition_importance = 0\n",
    "            \n",
    "            dates = list(rrule(\n",
    "                DAILY,\n",
    "                dtstart=datetime.strptime(start_date, '%Y-%m-%d') + timedelta(step),\n",
    "                until=datetime.strptime(end_date, '%Y-%m-%d') - timedelta(step),\n",
    "                interval=step,\n",
    "            ))\n",
    "            \n",
    "            print(f\"   Processing {len(dates)} dates...\")\n",
    "            print(\"   (This may take a while - suppressing verbose output)\\n\")\n",
    "            \n",
    "            import sys\n",
    "            import io\n",
    "            from tqdm import tqdm\n",
    "            \n",
    "            # Suppress verbose output from efast library\n",
    "            class SuppressOutput:\n",
    "                def __init__(self):\n",
    "                    self.stdout = io.StringIO()\n",
    "                    self.stderr = io.StringIO()\n",
    "                \n",
    "                def __enter__(self):\n",
    "                    self.old_stdout = sys.stdout\n",
    "                    self.old_stderr = sys.stderr\n",
    "                    sys.stdout = self.stdout\n",
    "                    sys.stderr = self.stderr\n",
    "                    return self\n",
    "                \n",
    "                def __exit__(self, *args):\n",
    "                    sys.stdout = self.old_stdout\n",
    "                    sys.stderr = self.old_stderr\n",
    "            \n",
    "            successful = 0\n",
    "            failed = 0\n",
    "            error_dates = []\n",
    "            \n",
    "            # Process dates with progress bar\n",
    "            for date in tqdm(dates, desc=\"Fusion progress\", unit=\"date\", ncols=80):\n",
    "                try:\n",
    "                    # Suppress verbose output from efast.fusion\n",
    "                    with SuppressOutput():\n",
    "                        efast.fusion(\n",
    "                            date,\n",
    "                            s3_reprojected_dir,\n",
    "                            s2_processed_dir,\n",
    "                            fusion_dir,\n",
    "                            product=\"REFL\",\n",
    "                            ratio=ratio,\n",
    "                            max_days=max_days,\n",
    "                            minimum_acquisition_importance=minimum_acquisition_importance,\n",
    "                        )\n",
    "                    successful += 1\n",
    "                except Exception as e:\n",
    "                    failed += 1\n",
    "                    error_dates.append((date.date(), str(e)))\n",
    "                    # Only show first few errors to avoid clutter\n",
    "                    if failed <= 5:\n",
    "                        error_msg = str(e).split('\\n')[0]  # Get first line only\n",
    "                        print(f\"\\n   ‚ö†Ô∏è Error for {date.date()}: {error_msg[:80]}\")\n",
    "            \n",
    "            # Summary of errors\n",
    "            if failed > 5:\n",
    "                print(f\"\\n   ... and {failed - 5} more errors (see summary below)\")\n",
    "            \n",
    "            print(f\"\\n‚úÖ Fusion complete!\")\n",
    "            print(f\"   Successful: {successful}/{len(dates)} ({successful/len(dates)*100:.1f}%)\")\n",
    "            if failed > 0:\n",
    "                print(f\"   Failed: {failed}/{len(dates)} ({failed/len(dates)*100:.1f}%)\")\n",
    "                if failed <= 10:\n",
    "                    print(f\"\\n   Failed dates:\")\n",
    "                    for date, error in error_dates:\n",
    "                        error_short = error.split('\\n')[0][:60]\n",
    "                        print(f\"     - {date}: {error_short}\")\n",
    "                else:\n",
    "                    print(f\"\\n   First 10 failed dates:\")\n",
    "                    for date, error in error_dates[:10]:\n",
    "                        error_short = error.split('\\n')[0][:60]\n",
    "                        print(f\"     - {date}: {error_short}\")\n",
    "                    print(f\"     ... and {failed - 10} more\")\n",
    "            print(f\"\\nüí° Re-run this cell to refresh status\")\n",
    "        except Exception as e:\n",
    "            print(f\"‚ùå Error: {e}\")\n",
    "            import traceback\n",
    "            traceback.print_exc()\n",
    "\n",
    "fusion_button.on_click(run_fusion)\n",
    "\n",
    "print(\"=\" * 60)\n",
    "print(\"üìä FUSION STATUS\")\n",
    "print(\"=\" * 60)\n",
    "print(f\"Fusion Results: {'‚úÖ' if fusion_count > 0 else '‚ùå'} {fusion_count} files\")\n",
    "if start_date and end_date:\n",
    "    print(f\"Date range: {start_date} to {end_date}\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "display(widgets.VBox([fusion_button, fusion_output]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Verify Results\n",
    "\n",
    "Three core visualizations for verification:\n",
    "1. **Basic Statistics** - Data validity and consistency\n",
    "2. **RGB Comparison** - Spatial quality (S2 vs S3 vs Fusion)\n",
    "3. **Time Series** - Temporal smoothness\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.1 Basic Statistics\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Basic Statistics - Data validity and consistency\n",
    "\n",
    "if not RASTERIO_AVAILABLE:\n",
    "    print(\"‚ö†Ô∏è Install rasterio for visualization\")\n",
    "elif 'filtered_fusion' not in globals():\n",
    "    print(\"‚ùå Variables not found. Run the data loading cell (Cell 5) first.\")\n",
    "elif not filtered_fusion:\n",
    "    print(\"‚ö†Ô∏è  No fusion files found!\")\n",
    "    print(f\"   The fusion_results directory exists but is empty.\")\n",
    "    print(f\"   üí° You need to run the EFAST fusion step first.\")\n",
    "    print(f\"   Run: python run_efast.py (or use the fusion function)\")\n",
    "    print(f\"\\n   Available data:\")\n",
    "    print(f\"   - S2 files: {len(s2_files) if 's2_files' in globals() else 0}\")\n",
    "    print(f\"   - S3 composites: {len(s3_composites) if 's3_composites' in globals() else 0}\")\n",
    "    print(f\"\\n   You can still verify S2 and S3 data, but fusion results are needed for full verification.\")\n",
    "else:\n",
    "    print(\"=\" * 70)\n",
    "    print(\"1Ô∏è‚É£  BASIC STATISTICS\")\n",
    "    print(\"=\" * 70)\n",
    "    \n",
    "    stats_data = []\n",
    "    for fusion_file in filtered_fusion[:10]:  # Sample first 10 files\n",
    "        try:\n",
    "            with rasterio.open(fusion_file) as src:\n",
    "                data = src.read()\n",
    "                date_str = fusion_file.stem.split('_')[1]\n",
    "                \n",
    "                file_stats = {\n",
    "                    'date': date_str,\n",
    "                    'shape': data.shape,\n",
    "                    'bands': data.shape[0],\n",
    "                    'valid_pixels': [],\n",
    "                    'min': [],\n",
    "                    'max': [],\n",
    "                    'mean': [],\n",
    "                    'std': []\n",
    "                }\n",
    "                \n",
    "                for band_idx in range(data.shape[0]):\n",
    "                    band_data = data[band_idx].astype(float)\n",
    "                    valid = ~np.isnan(band_data)\n",
    "                    valid_count = np.sum(valid)\n",
    "                    \n",
    "                    if valid_count > 0:\n",
    "                        valid_data = band_data[valid]\n",
    "                        file_stats['valid_pixels'].append(valid_count)\n",
    "                        file_stats['min'].append(np.min(valid_data))\n",
    "                        file_stats['max'].append(np.max(valid_data))\n",
    "                        file_stats['mean'].append(np.mean(valid_data))\n",
    "                        file_stats['std'].append(np.std(valid_data))\n",
    "                    else:\n",
    "                        file_stats['valid_pixels'].append(0)\n",
    "                        file_stats['min'].append(np.nan)\n",
    "                        file_stats['max'].append(np.nan)\n",
    "                        file_stats['mean'].append(np.nan)\n",
    "                        file_stats['std'].append(np.nan)\n",
    "                \n",
    "                stats_data.append(file_stats)\n",
    "                print(f\"üìÖ {date_str}: {data.shape[1]}x{data.shape[2]} pixels, {data.shape[0]} bands\")\n",
    "                print(f\"   Band 1 (Red):   min={file_stats['min'][0]:.4f}, max={file_stats['max'][0]:.4f}, mean={file_stats['mean'][0]:.4f}\")\n",
    "                if len(file_stats['min']) > 1:\n",
    "                    print(f\"   Band 2 (Green): min={file_stats['min'][1]:.4f}, max={file_stats['max'][1]:.4f}, mean={file_stats['mean'][1]:.4f}\")\n",
    "                if len(file_stats['min']) > 2:\n",
    "                    print(f\"   Band 3 (Blue):  min={file_stats['min'][2]:.4f}, max={file_stats['max'][2]:.4f}, mean={file_stats['mean'][2]:.4f}\")\n",
    "                print()\n",
    "        except Exception as e:\n",
    "            print(f\"   ‚ö†Ô∏è Error reading {fusion_file.name}: {e}\\n\")\n",
    "    \n",
    "    # Check consistency\n",
    "    if len(stats_data) > 1:\n",
    "        means_band1 = [s['mean'][0] for s in stats_data if not np.isnan(s['mean'][0])]\n",
    "        if means_band1:\n",
    "            mean_std = np.std(means_band1)\n",
    "            print(f\"üìä Temporal consistency: Band 1 mean std across dates = {mean_std:.4f}\")\n",
    "            if mean_std < 0.1:\n",
    "                print(\"   ‚úÖ Values are consistent across dates\")\n",
    "            else:\n",
    "                print(\"   ‚ö†Ô∏è  Values vary significantly (may indicate issues)\")\n",
    "    \n",
    "    print(\"=\" * 70)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.2 RGB Comparison (S2 vs S3 vs Fusion)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. RGB Side-by-Side Comparison - Spatial quality verification\n",
    "\n",
    "if not RASTERIO_AVAILABLE:\n",
    "    print(\"‚ö†Ô∏è Install rasterio for visualization\")\n",
    "elif 'filtered_fusion' not in globals():\n",
    "    print(\"‚ùå Variables not found. Run the data loading cell (Cell 5) first.\")\n",
    "elif not filtered_fusion:\n",
    "    print(\"‚ö†Ô∏è  No fusion files found!\")\n",
    "    print(f\"   Cannot show fusion comparison without fusion results.\")\n",
    "    print(f\"   üí° Run the EFAST fusion step first, then rerun this cell.\")\n",
    "    \n",
    "    # Still show S2/S3 comparison if available\n",
    "    if 's2_files' in globals() and s2_files and 's3_composites' in globals() and s3_composites:\n",
    "        print(f\"\\n   Showing S2 vs S3 comparison instead...\")\n",
    "        try:\n",
    "            s2_file = s2_files[0]\n",
    "            s3_file = s3_composites[len(s3_composites) // 2]\n",
    "            \n",
    "            fig, axes = plt.subplots(1, 2, figsize=(14, 6))\n",
    "            \n",
    "            # S2\n",
    "            with rasterio.open(s2_file) as src:\n",
    "                red = src.read(3).astype(float)\n",
    "                green = src.read(2).astype(float)\n",
    "                blue = src.read(1).astype(float)\n",
    "                rgb = np.dstack((red, green, blue))\n",
    "                rgb[rgb == src.nodata] = np.nan\n",
    "                rgb = np.clip(rgb / 3000.0, 0, 1)\n",
    "                axes[0].imshow(rgb)\n",
    "                axes[0].set_title('S2 Original (High-Res)', fontsize=12, fontweight='bold')\n",
    "                axes[0].axis('off')\n",
    "            \n",
    "            # S3\n",
    "            with rasterio.open(s3_file) as src:\n",
    "                data = src.read(1).astype(float)\n",
    "                data[data == src.nodata] = np.nan\n",
    "                im = axes[1].imshow(data, cmap='RdYlGn', vmin=0, vmax=0.8)\n",
    "                axes[1].set_title('S3 Low-Res', fontsize=12, fontweight='bold')\n",
    "                axes[1].axis('off')\n",
    "                plt.colorbar(im, ax=axes[1], fraction=0.046)\n",
    "            \n",
    "            plt.suptitle('S2 vs S3 Comparison (Fusion results not available)', \n",
    "                        fontsize=14, fontweight='bold')\n",
    "            plt.tight_layout()\n",
    "            plt.show()\n",
    "        except Exception as e:\n",
    "            print(f\"   ‚ö†Ô∏è Error showing S2/S3 comparison: {e}\")\n",
    "else:\n",
    "    print(\"=\" * 70)\n",
    "    print(\"2Ô∏è‚É£  RGB COMPARISON (S2 vs S3 vs Fusion)\")\n",
    "    print(\"=\" * 70)\n",
    "    \n",
    "    # Find a fusion file and try to match with S2/S3\n",
    "    fusion_file = filtered_fusion[len(filtered_fusion) // 2]  # Middle file\n",
    "    fusion_date_str = fusion_file.stem.split('_')[1]\n",
    "    fusion_date = datetime.strptime(fusion_date_str, '%Y%m%d')\n",
    "    \n",
    "    print(f\"üìÖ Comparing date: {fusion_date.strftime('%Y-%m-%d')}\\n\")\n",
    "    \n",
    "    # Find closest S2 file\n",
    "    s2_match = None\n",
    "    min_diff = float('inf')\n",
    "    for s2_file in s2_files:\n",
    "        try:\n",
    "            date_str = s2_file.stem.split('_')[2]\n",
    "            s2_date = datetime.strptime(date_str, '%Y%m%d')\n",
    "            diff = abs((s2_date - fusion_date).days)\n",
    "            if diff < min_diff:\n",
    "                min_diff = diff\n",
    "                s2_match = s2_file\n",
    "        except (IndexError, ValueError):\n",
    "            continue\n",
    "    \n",
    "    # Find closest S3 composite\n",
    "    s3_match = None\n",
    "    min_diff_s3 = float('inf')\n",
    "    for s3_file in s3_composites:\n",
    "        try:\n",
    "            if 'composite_' in s3_file.stem:\n",
    "                date_str = s3_file.stem.split('composite_')[1]\n",
    "                s3_date = datetime.strptime(date_str, '%Y-%m-%d')\n",
    "                diff = abs((s3_date - fusion_date).days)\n",
    "                if diff < min_diff_s3:\n",
    "                    min_diff_s3 = diff\n",
    "                    s3_match = s3_file\n",
    "        except (ValueError, IndexError):\n",
    "            continue\n",
    "    \n",
    "    # Create comparison figure\n",
    "    fig, axes = plt.subplots(1, 3, figsize=(18, 6))\n",
    "    \n",
    "    # S2 (if available)\n",
    "    if s2_match and min_diff <= 30:\n",
    "        try:\n",
    "            with rasterio.open(s2_match) as src:\n",
    "                red = src.read(3).astype(float)\n",
    "                green = src.read(2).astype(float)\n",
    "                blue = src.read(1).astype(float)\n",
    "                rgb = np.dstack((red, green, blue))\n",
    "                rgb[rgb == src.nodata] = np.nan\n",
    "                rgb = np.clip(rgb / 3000.0, 0, 1)\n",
    "                \n",
    "                axes[0].imshow(rgb)\n",
    "                axes[0].set_title(f'S2 Original\\n({min_diff} days from fusion)', \n",
    "                                 fontsize=12, fontweight='bold')\n",
    "                axes[0].axis('off')\n",
    "        except Exception as e:\n",
    "            axes[0].text(0.5, 0.5, f'S2 not available\\n({e})', \n",
    "                        ha='center', va='center', transform=axes[0].transAxes)\n",
    "            axes[0].axis('off')\n",
    "    else:\n",
    "        axes[0].text(0.5, 0.5, 'S2 not available\\n(no matching date)', \n",
    "                    ha='center', va='center', transform=axes[0].transAxes)\n",
    "        axes[0].axis('off')\n",
    "    \n",
    "    # S3 (if available)\n",
    "    if s3_match and min_diff_s3 <= 30:\n",
    "        try:\n",
    "            with rasterio.open(s3_match) as src:\n",
    "                data = src.read(1).astype(float)\n",
    "                data[data == src.nodata] = np.nan\n",
    "                \n",
    "                im = axes[1].imshow(data, cmap='RdYlGn', vmin=0, vmax=0.8)\n",
    "                axes[1].set_title(f'S3 Low-Res\\n({min_diff_s3} days from fusion)', \n",
    "                                 fontsize=12, fontweight='bold')\n",
    "                axes[1].axis('off')\n",
    "                plt.colorbar(im, ax=axes[1], fraction=0.046)\n",
    "        except Exception as e:\n",
    "            axes[1].text(0.5, 0.5, f'S3 not available\\n({e})', \n",
    "                        ha='center', va='center', transform=axes[1].transAxes)\n",
    "            axes[1].axis('off')\n",
    "    else:\n",
    "        axes[1].text(0.5, 0.5, 'S3 not available\\n(no matching date)', \n",
    "                    ha='center', va='center', transform=axes[1].transAxes)\n",
    "        axes[1].axis('off')\n",
    "    \n",
    "    # Fusion result\n",
    "    try:\n",
    "        with rasterio.open(fusion_file) as src:\n",
    "            red = src.read(3).astype(float) if src.count >= 3 else src.read(1).astype(float)\n",
    "            green = src.read(2).astype(float) if src.count >= 2 else src.read(1).astype(float)\n",
    "            blue = src.read(1).astype(float)\n",
    "            \n",
    "            rgb = np.dstack((red, green, blue))\n",
    "            rgb[rgb == src.nodata] = np.nan\n",
    "            rgb = np.clip(rgb / 3000.0, 0, 1)\n",
    "            \n",
    "            axes[2].imshow(rgb)\n",
    "            axes[2].set_title(f'Fusion Result\\n(High-Res Daily)', \n",
    "                            fontsize=12, fontweight='bold')\n",
    "            axes[2].axis('off')\n",
    "    except Exception as e:\n",
    "        axes[2].text(0.5, 0.5, f'Error loading fusion\\n({e})', \n",
    "                    ha='center', va='center', transform=axes[2].transAxes)\n",
    "        axes[2].axis('off')\n",
    "    \n",
    "    plt.suptitle(f'RGB Comparison - {sitename} ({season_year or \"all seasons\"})', \n",
    "                fontsize=14, fontweight='bold')\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    print(\"=\" * 70)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.3 Time Series (Temporal Smoothness)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3. Time Series Plot - Temporal smoothness verification\n",
    "\n",
    "if not RASTERIO_AVAILABLE:\n",
    "    print(\"‚ö†Ô∏è Install rasterio for visualization\")\n",
    "elif 'filtered_fusion' not in globals():\n",
    "    print(\"‚ùå Variables not found. Run the data loading cell (Cell 5) first.\")\n",
    "elif not filtered_fusion:\n",
    "    print(\"‚ö†Ô∏è  No fusion files found!\")\n",
    "    print(f\"   Cannot create fusion time series without fusion results.\")\n",
    "    print(f\"   üí° Run the EFAST fusion step first, then rerun this cell.\")\n",
    "    \n",
    "    # Show S3 time series as alternative\n",
    "    if 's3_composites' in globals() and s3_composites:\n",
    "        print(f\"\\n   Showing S3 composite time series instead...\")\n",
    "        try:\n",
    "            dates_ts = []\n",
    "            values = []\n",
    "            \n",
    "            for comp_file in s3_composites[:50]:  # Limit to first 50\n",
    "                try:\n",
    "                    with rasterio.open(comp_file) as src:\n",
    "                        data = src.read(1).astype(float)\n",
    "                        data[data == src.nodata] = np.nan\n",
    "                        h, w = data.shape\n",
    "                        center_val = data[h//2, w//2]\n",
    "                        if not np.isnan(center_val):\n",
    "                            if 'composite_' in comp_file.stem:\n",
    "                                date_str = comp_file.stem.split('composite_')[1]\n",
    "                                dates_ts.append(datetime.strptime(date_str, '%Y-%m-%d'))\n",
    "                                values.append(center_val)\n",
    "                except Exception as e:\n",
    "                    continue\n",
    "            \n",
    "            if dates_ts and values:\n",
    "                fig, ax = plt.subplots(figsize=(14, 6))\n",
    "                ax.plot(dates_ts, values, marker='o', markersize=4, linewidth=2, \n",
    "                       color='green', alpha=0.7, label='S3 Composite')\n",
    "                ax.set_xlabel('Date', fontsize=12, fontweight='bold')\n",
    "                ax.set_ylabel('Reflectance (center pixel)', fontsize=12, fontweight='bold')\n",
    "                ax.set_title(f'S3 Composite Time Series - {sitename if \"sitename\" in globals() else \"unknown\"}\\n(Fusion results not available)', \n",
    "                           fontsize=13, fontweight='bold')\n",
    "                ax.legend(loc='best', fontsize=10)\n",
    "                ax.grid(True, alpha=0.3)\n",
    "                plt.xticks(rotation=45)\n",
    "                plt.tight_layout()\n",
    "                plt.show()\n",
    "        except Exception as e:\n",
    "            print(f\"   ‚ö†Ô∏è Error creating S3 time series: {e}\")\n",
    "else:\n",
    "    print(\"=\" * 70)\n",
    "    print(\"3Ô∏è‚É£  TIME SERIES (Temporal Smoothness)\")\n",
    "    print(\"=\" * 70)\n",
    "    \n",
    "    # Extract time series from center pixel\n",
    "    dates_ts = []\n",
    "    values_band1 = []\n",
    "    values_band2 = []\n",
    "    values_band3 = []\n",
    "    \n",
    "    for fusion_file in filtered_fusion:\n",
    "        try:\n",
    "            with rasterio.open(fusion_file) as src:\n",
    "                data = src.read()\n",
    "                date_str = fusion_file.stem.split('_')[1]\n",
    "                date_obj = datetime.strptime(date_str, '%Y%m%d')\n",
    "                \n",
    "                h, w = data.shape[1], data.shape[2]\n",
    "                center_h, center_w = h // 2, w // 2\n",
    "                \n",
    "                # Extract center pixel values\n",
    "                val1 = data[0, center_h, center_w] if not np.isnan(data[0, center_h, center_w]) else None\n",
    "                val2 = data[1, center_h, center_w] if data.shape[0] > 1 and not np.isnan(data[1, center_h, center_w]) else None\n",
    "                val3 = data[2, center_h, center_w] if data.shape[0] > 2 and not np.isnan(data[2, center_h, center_w]) else None\n",
    "                \n",
    "                if val1 is not None:\n",
    "                    dates_ts.append(date_obj)\n",
    "                    values_band1.append(float(val1))\n",
    "                    values_band2.append(float(val2) if val2 is not None else np.nan)\n",
    "                    values_band3.append(float(val3) if val3 is not None else np.nan)\n",
    "        except Exception as e:\n",
    "            continue\n",
    "    \n",
    "    if dates_ts and values_band1:\n",
    "        try:\n",
    "            fig, ax = plt.subplots(figsize=(14, 6))\n",
    "            \n",
    "            ax.plot(dates_ts, values_band1, marker='o', markersize=4, linewidth=2, \n",
    "                   label='Band 1 (Red)', color='red', alpha=0.7)\n",
    "            if any(not np.isnan(v) for v in values_band2):\n",
    "                ax.plot(dates_ts, values_band2, marker='s', markersize=4, linewidth=2, \n",
    "                       label='Band 2 (Green)', color='green', alpha=0.7)\n",
    "            if any(not np.isnan(v) for v in values_band3):\n",
    "                ax.plot(dates_ts, values_band3, marker='^', markersize=4, linewidth=2, \n",
    "                       label='Band 3 (Blue)', color='blue', alpha=0.7)\n",
    "            \n",
    "            ax.set_xlabel('Date', fontsize=12, fontweight='bold')\n",
    "            ax.set_ylabel('Reflectance (center pixel)', fontsize=12, fontweight='bold')\n",
    "            ax.set_title(f'Fusion Time Series - {sitename} ({season_year or \"all seasons\"})\\nCenter Pixel Values', \n",
    "                       fontsize=13, fontweight='bold')\n",
    "            ax.legend(loc='best', fontsize=10)\n",
    "            ax.grid(True, alpha=0.3)\n",
    "            plt.xticks(rotation=45)\n",
    "            plt.tight_layout()\n",
    "            plt.show()\n",
    "            \n",
    "            # Check for temporal smoothness\n",
    "            if len(values_band1) > 1:\n",
    "                diffs = np.abs(np.diff(values_band1))\n",
    "                max_jump = np.max(diffs)\n",
    "                mean_jump = np.mean(diffs)\n",
    "                print(f\"üìä Temporal smoothness (Band 1):\")\n",
    "                print(f\"   Mean change between dates: {mean_jump:.4f}\")\n",
    "                print(f\"   Max jump: {max_jump:.4f}\")\n",
    "                if max_jump < 0.2:\n",
    "                    print(\"   ‚úÖ Smooth temporal transitions\")\n",
    "                elif max_jump < 0.5:\n",
    "                    print(\"   ‚ö†Ô∏è  Some temporal variability (may be normal)\")\n",
    "                else:\n",
    "                    print(\"   ‚ö†Ô∏è  Large temporal jumps detected (check for artifacts)\")\n",
    "        except Exception as e:\n",
    "            print(f\"   ‚ö†Ô∏è Error creating time series: {e}\")\n",
    "    else:\n",
    "        print(\"   ‚ö†Ô∏è Could not extract time series data\")\n",
    "    \n",
    "    print(\"=\" * 70)\n",
    "    print(\"‚úÖ Verification complete!\")\n",
    "    print(\"=\" * 70)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
